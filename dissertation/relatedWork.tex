\chapter{Related Work} 
\label{chap:relWork}

\section{Probabilistic Programming Languages}
\label{sect:ppl}
With the fast increase in both breadth and specialization of probabilistic models, the need for tools which make the modelling task easier has grown sharply. Many different probabilistic programming languages have arisen to fill this gap. At their core probabilistic programming languages are tools that formalise a model specification by providing the user with stochastic primitives with which to define their model. Given this formalisation the PPL can then attempt to automatically perform inference on the user's model. While the foundation for these stochastic languages was set a long time ago (eg: \cite{jones1989probabilistic}), there has been a recent explosion in the popularity of PPLs. Probabilistic languages have now arisen to fill many different modelling niches by juggling tradeoffs such as efficiency, expressivity and ease of use. 

It is beyond the scope of this work to go into details about all the various PPLs (see \cite{ppw} for a short summary of some of the most well known PPLs), but we shall briefly list a few different paradigms, just to give an idea of the diversity of PPLs. The logic programming paradigm has atracted quite a few probabilistic extensions (\cite{kimmig2011implementation, de2008probabilistic, sato1997prism, poole2008independent}) which are used for tasks such as symbolic-statistical modeling and statistical relational learning. Other PPLs adopt a functional programming paradigm (\cite{goodman2008church, mansinghka2014venture, wood2014new}), by extending LISP \cite{abelson1991revised} which, being a higher-order language, gives the user a large degree of flexibility over his probabilistic program specification. Some methods for creating embedded, domain specific, PPLs have also emerged \cite{kiselyov2009embedded}. Finally, BUGS is an example of a PPL that does not extend a previous programming language, but instead defines a simple, bespoke, language that emphasizes usability, since it enables the user to define their model in a declarative fashion \cite{lunn2009bugs}.

Switching to another criteria, some PPLs focus on efficiency at the cost of expressivity, generally by restricting themselves to programs that can be compiled into finite graphical models \cite{lunn2009bugs, richardson2006markov, mccallum2009factorie, stan-software:2014, minkainfer}. Other PPLs emphasize flexibility and expresiveness (\cite{milch20071, pfeffer2001ibal, pfeffer2009figaro, goodman2008church}), by allowing the user to specify programs that cannot be expressed as graphical models and that therefore can't make use of the standard graphical model inference methods. Church and Venture are the two languages that pehaps focus most on flexibility from the above, which is what makes them well suited for complex, potentially recursive, reasoning tasks like the cognition models briefly mentioned in Section \ref{sect:betInf}.

It is based on these criteria that we decided to compare two popular PPLs. Namely the efficient, declarative, OpenBUGS and the flexible, functional Venture.

\section{Speeding up inference}

As we saw in Section \ref{sect:betInf}, one of the crucial problems that must be solved before PPLs can reach their promise is that of efficient, general inference. Many attempts have been made towards this goal. One possibility is to perform exact inference by applying dynamic programming (DP) techniques to manage the exponential number of possible execution paths \cite{stuhlmuller2012dynamic}. There is potential for future work in this area by analysing the performance of different DP and approximate-DP techniques. More generally, it is clear that DP wonâ€™t work on all models, but understanding what the subclass of models is on which exact inference might be tractable would be very useful to known, from a PPL designer's point of view.

When exact inference is intractable, we have to settle for approximate solutions, usually obtained via Markov chain Monte Carlo (MCMC). Figuring out how to best take advantage of the underlying structure
of the distributions, as to obtain better mixing rates and therefore faster inference, is currently an area of active research. Two broad approaches here are to compile the probabilistic program into a form more amenable to efficient inference, or to implement novel inference techniques which can achieve better performance on some class of models.

In the program compilation category, one attempt uses nonstandard interpretations to create monad-like side computations which can extract structural information, such as gradients \cite{wingate2011nonstandard}. This information can then enable the use of sophisticated MCMC techniques, such as Hamiltonian MC, which can lead to big boosts in performance over Metropolis-Hastings and other naive MCMC methods. There seems to be much potential in further improving inference through the application of compiler design and program analysis techniques. For instance, speed-ups of over an order of magnitude were shown to be possible by applying techniques such as JIT compilation, dead code elimination, allocation removal and incremental optimization \cite{yang2013incrementalizing}. Our partitioned prior idea also falls in the program compilation category and is, asa far as we can tell, a novel program transformation.

Regarding the implementation of new inference methods, one recent attempt \cite{wood2014new} looked at the application of particle MCMC towards inference on probabilistic programs. The authors implement particle MCMC in a Turing Complete functional language and show that their implementation outperforms Metropolis-Hastings on certain models while also being very easy to parallelize. Other inference methods which specialized to a small niche have also been proposed. For instance, in \cite{yeh2012synthesizing} the authors propose a method called ``locally annealed reversible jump MCMC'' which they show to be very efficient at the computer graphics problem of synthesizing open world layouts. Our implementation of slice sampling as a inference technique in PPLs has also shown to outperform the default Metropolis-Hastings algorithm on some models and, assuming the trans-dimensionality issue is solvable, should prove a valuable addition to the inference toolbelt available to PPL designers.
