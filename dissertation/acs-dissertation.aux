\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{1}{section.1.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Comparing Venture and OpenBUGS}{5}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Motivation}{5}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Preliminaries}{6}{section.3.2}}
\@writefile{tdo}{\contentsline {todo}{{Add background info on Venture and OpenBUGS}}{6}{section*.4}}
\pgfsyspdfmark {pgfid1}{9913630}{40713507}
\pgfsyspdfmark {pgfid2}{5539101}{41495958}
\pgfsyspdfmark {pgfid3}{9159964}{40501932}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Number of MCMC steps}{6}{subsection.3.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Strategies for extracting S samples from a model with V unconditioned variables\relax }}{6}{table.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:noSteps}{{3.1}{6}{Strategies for extracting S samples from a model with V unconditioned variables\relax \relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Empirical results}{6}{section.3.3}}
\@writefile{tdo}{\contentsline {todo}{{Maybe also evaluate one model that's not from the OpenBUGS repository, since BUGS might be unreasonably optimized on its own models.}}{7}{section*.6}}
\pgfsyspdfmark {pgfid6}{9284914}{46661975}
\pgfsyspdfmark {pgfid9}{33522973}{43711464}
\pgfsyspdfmark {pgfid10}{37143836}{40317168}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Tdf model description}{7}{subsection.3.3.1}}
\@writefile{tdo}{\contentsline {todo}{{add model pseudocode}}{7}{section*.7}}
\pgfsyspdfmark {pgfid11}{13014102}{32768759}
\pgfsyspdfmark {pgfid14}{33522973}{33059690}
\pgfsyspdfmark {pgfid15}{37143836}{32557184}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Tdf model true posteriors}{7}{subsection.3.3.2}}
\newlabel{sect:truePost}{{3.3.2}{7}{Tdf model true posteriors\relax }{subsection.3.3.2}{}}
\@writefile{tdo}{\contentsline {todo}{Figure: {Add formula used to derive posterior, as in the log}}{7}{subsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces True posterior distributions for the 3 Tdf models.\relax }}{8}{figure.caption.8}}
\newlabel{fig:tdfPosts}{{3.1}{8}{True posterior distributions for the 3 Tdf models.\relax \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Tdf model results}{8}{subsection.3.3.3}}
\@writefile{tdo}{\contentsline {todo}{{Add KL and KS difference results for these distributions}}{8}{section*.9}}
\pgfsyspdfmark {pgfid17}{9913630}{33036598}
\pgfsyspdfmark {pgfid18}{5539101}{34253239}
\pgfsyspdfmark {pgfid19}{9159964}{32825023}
\newlabel{fig:tdfCourseDiscSamp}{{3.2a}{8}{Distributions obtained by the two PPLs on the course discrete model.\relax \relax }{figure.caption.10}{}}
\newlabel{sub@fig:tdfCourseDiscSamp}{{a}{8}{Distributions obtained by the two PPLs on the course discrete model.\relax \relax }{figure.caption.10}{}}
\newlabel{fig:tdfCourseDiscConv}{{3.2b}{8}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.10}{}}
\newlabel{sub@fig:tdfCourseDiscConv}{{b}{8}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Performance of the Tdf course discrete model\relax }}{8}{figure.caption.10}}
\@writefile{tdo}{\contentsline {todo}{{Maybe do more runs and plot quartiles}}{8}{section*.11}}
\pgfsyspdfmark {pgfid22}{9913630}{8126807}
\pgfsyspdfmark {pgfid23}{5539101}{8909258}
\pgfsyspdfmark {pgfid24}{9159964}{7915232}
\newlabel{fig:tdfFineDiscSamp}{{3.3a}{9}{Distributions obtained by the two PPLs on the fine discrete model.\relax \relax }{figure.caption.12}{}}
\newlabel{sub@fig:tdfFineDiscSamp}{{a}{9}{Distributions obtained by the two PPLs on the fine discrete model.\relax \relax }{figure.caption.12}{}}
\newlabel{fig:tdfFineDiscConv}{{3.3b}{9}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.12}{}}
\newlabel{sub@fig:tdfFineDiscConv}{{b}{9}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Performance of the Tdf fine discrete model\relax }}{9}{figure.caption.12}}
\newlabel{fig:tdfContSamp}{{3.4a}{10}{Distributions obtained by the two PPLs on the continuous model.\relax \relax }{figure.caption.13}{}}
\newlabel{sub@fig:tdfContSamp}{{a}{10}{Distributions obtained by the two PPLs on the continuous model.\relax \relax }{figure.caption.13}{}}
\newlabel{fig:tdfContConv}{{3.4b}{10}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KS difference achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.13}{}}
\newlabel{sub@fig:tdfContConv}{{b}{10}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KS difference achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Performance of the Tdf continuous model\relax }}{10}{figure.caption.13}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Analysis of Venture's performance}{10}{section.3.4}}
\@writefile{tdo}{\contentsline {todo}{{saw this mentioned in a paper, need to find direct source or remove}}{10}{section*.15}}
\pgfsyspdfmark {pgfid27}{29584909}{10092887}
\pgfsyspdfmark {pgfid28}{5539101}{11309528}
\pgfsyspdfmark {pgfid29}{9159964}{9881312}
\@writefile{tdo}{\contentsline {todo}{{Decide is there's anything worth reporting from the performance tests done on Venture. Log dates: 2014.02.19 and 2014.02.20}}{10}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Number and size of identical sample runs generated by the two PPLs on the continuous model.\relax }}{11}{figure.caption.14}}
\newlabel{fig:tdfContRun}{{3.5}{11}{Number and size of identical sample runs generated by the two PPLs on the continuous model.\relax \relax }{figure.caption.14}{}}
\pgfsyspdfmark {pgfid32}{6571294}{26078691}
\pgfsyspdfmark {pgfid35}{33522973}{23619700}
\pgfsyspdfmark {pgfid36}{37143836}{20716924}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Webchurch's performance}{11}{subsection.3.4.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Partitioned Priors}{13}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{{say something about proposal kernels vs. sampling from prior?}}{13}{section*.17}}
\pgfsyspdfmark {pgfid37}{21955754}{28596487}
\pgfsyspdfmark {pgfid40}{33522973}{29870458}
\pgfsyspdfmark {pgfid41}{37143836}{28384912}
\@writefile{tdo}{\contentsline {todo}{{not sure if this makes much sense. Need to research it more or remove}}{13}{section*.18}}
\pgfsyspdfmark {pgfid42}{22024914}{18791974}
\pgfsyspdfmark {pgfid45}{33522973}{20008615}
\pgfsyspdfmark {pgfid46}{37143836}{18580399}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preliminaries}{13}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Local Metropolis-Hastings}{14}{subsection.4.1.1}}
\@writefile{tdo}{\contentsline {todo}{{add basic explanation}}{14}{section*.19}}
\pgfsyspdfmark {pgfid47}{9913630}{40369753}
\pgfsyspdfmark {pgfid48}{5539101}{40660684}
\pgfsyspdfmark {pgfid49}{9159964}{40158178}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Expected number of iterations to a neighbourhood of the mode}{14}{subsection.4.1.2}}
\newlabel{section:sampsToMode}{{4.1.2}{14}{Expected number of iterations to a neighbourhood of the mode\relax }{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Mixing properties around the mode}{14}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Sum of uniforms}{15}{section.4.2}}
\newlabel{sect:sumUnif}{{4.2}{15}{Sum of uniforms\relax }{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Prior distribution induced by partitioning the prior (uniform-continuous 2 100) into (uniform-continuous 2 95) + (uniform-continuous 0 2) (uniform-continuous 0 1).\relax }}{15}{figure.caption.20}}
\newlabel{fig:1295Prior}{{4.1}{15}{Prior distribution induced by partitioning the prior (uniform-continuous 2 100) into (uniform-continuous 2 95) + (uniform-continuous 0 2) (uniform-continuous 0 1).\relax \relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Finding a good sum decomposition}{16}{subsection.4.2.1}}
\newlabel{sect:goodSum}{{4.2.1}{16}{Finding a good sum decomposition\relax }{subsection.4.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Expected number of steps to neighbourhoods of the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax }}{16}{table.caption.21}}
\newlabel{tab:bestParts}{{4.1}{16}{Expected number of steps to neighbourhoods of the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax \relax }{table.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Average distance travelled around the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax }}{17}{table.caption.22}}
\newlabel{tab:bestParts}{{4.2}{17}{Average distance travelled around the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax \relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Evaluating the (1,2,95) sum decomposition}{17}{subsection.4.2.2}}
\newlabel{sect:1295Eval}{{4.2.2}{17}{Evaluating the (1,2,95) sum decomposition\relax }{subsection.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples.\relax }}{18}{figure.caption.23}}
\newlabel{fig:tdfPSampEvol}{{4.2}{18}{Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples.\relax \relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{18}{figure.caption.24}}
\newlabel{fig:tdfPAutoCorr}{{4.3}{18}{Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{19}{figure.caption.25}}
\newlabel{fig:tdfPDist}{{4.4}{19}{Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Tdf21 model}{19}{section*.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The true posteriors of the Tdf continuous and the Tdf21 continuous models.\relax }}{19}{figure.caption.27}}
\newlabel{fig:tdfPPost}{{4.5}{19}{The true posteriors of the Tdf continuous and the Tdf21 continuous models.\relax \relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The true log-likelihoods of the Tdf continuous and the Tdf21 continuous models.\relax }}{20}{figure.caption.28}}
\newlabel{fig:tdfPLL}{{4.6}{20}{The true log-likelihoods of the Tdf continuous and the Tdf21 continuous models.\relax \relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluating the decomposition on the Tdf21 model}{20}{section*.29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{20}{figure.caption.30}}
\newlabel{fig:tdf21PSampEvol}{{4.7}{20}{Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{21}{figure.caption.31}}
\newlabel{fig:tdf21PAutoCorr}{{4.8}{21}{Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{21}{figure.caption.32}}
\newlabel{fig:tdf21PSampDist}{{4.9}{21}{Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Bit decomposition}{21}{section.4.3}}
\newlabel{sect:bitDecomp}{{4.3}{21}{Bit decomposition\relax }{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Definition}{22}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Evaluation on Tdf and Tdf21}{22}{subsection.4.3.2}}
\@writefile{tdo}{\contentsline {todo}{{Should be possible to give some more formal results here.}}{22}{section*.33}}
\pgfsyspdfmark {pgfid52}{22406693}{21433985}
\pgfsyspdfmark {pgfid53}{5539101}{22650626}
\pgfsyspdfmark {pgfid54}{9159964}{21222410}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Sample distributions for an unpartitioned and a 3 bit decomposition prior, over 10,000 samples on the Tdf model.\relax }}{22}{figure.caption.34}}
\newlabel{fig:tdf21PSampDist}{{4.10}{22}{Sample distributions for an unpartitioned and a 3 bit decomposition prior, over 10,000 samples on the Tdf model.\relax \relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Sample distributions for an unpartitioned and a 3 bit decomposition prios, over 10,000 samples on the Tdf21 model.\relax }}{23}{figure.caption.35}}
\newlabel{fig:tdf21PSampDist}{{4.11}{23}{Sample distributions for an unpartitioned and a 3 bit decomposition prios, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.35}{}}
\@writefile{tdo}{\contentsline {todo}{{talk about how binomials of different depth perform here}}{23}{section*.36}}
\pgfsyspdfmark {pgfid57}{24666102}{32878423}
\pgfsyspdfmark {pgfid60}{33522973}{33802742}
\pgfsyspdfmark {pgfid61}{37143836}{32317196}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Expected number of steps to neighbourhoods of the mode on the Tdf and Tdf21 continuous models for an unpartitioned prior, the (1,2,95) sum decomposition and 2 bit decompositions.\relax }}{23}{table.caption.37}}
\newlabel{tab:bestParts}{{4.3}{23}{Expected number of steps to neighbourhoods of the mode on the Tdf and Tdf21 continuous models for an unpartitioned prior, the (1,2,95) sum decomposition and 2 bit decompositions.\relax \relax }{table.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Getting stuck on a bad sample}{23}{subsection.4.3.3}}
\@writefile{tdo}{\contentsline {todo}{{is a more thorough analysis feasible here?}}{24}{section*.38}}
\pgfsyspdfmark {pgfid62}{16092932}{18855986}
\pgfsyspdfmark {pgfid63}{5539101}{19638437}
\pgfsyspdfmark {pgfid64}{9159964}{18644411}
\@writefile{tdo}{\contentsline {todo}{{explain why this is wrong}}{25}{section*.39}}
\pgfsyspdfmark {pgfid67}{19571554}{31031795}
\pgfsyspdfmark {pgfid70}{33522973}{31814246}
\pgfsyspdfmark {pgfid71}{37143836}{30820220}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Mixtures of shifted bit decompositions}{25}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{Avoiding getting stuck}{25}{section*.40}}
\@writefile{toc}{\contentsline {subsubsection}{Empirical performance}{27}{section*.41}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Time to 0.001 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax }}{27}{figure.caption.42}}
\newlabel{fig:allShifts}{{4.12}{27}{Time to 0.001 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax \relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax }}{28}{figure.caption.43}}
\newlabel{fig:AllShiftsMax001}{{4.13}{28}{Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax \relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depth using a small number of shifts.\relax }}{28}{figure.caption.44}}
\newlabel{fig:fewShifts}{{4.14}{28}{Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depth using a small number of shifts.\relax \relax }{figure.caption.44}{}}
\@writefile{tdo}{\contentsline {todo}{{talk about distributions over shifts, and more about benefits/drawback of shifts and/or changing depths}}{29}{section*.45}}
\pgfsyspdfmark {pgfid72}{16903434}{45678935}
\pgfsyspdfmark {pgfid75}{33522973}{44637174}
\pgfsyspdfmark {pgfid76}{37143836}{42168588}
\@writefile{toc}{\contentsline {subsubsection}{Determining optimal shifts and shift transitions}{29}{section*.46}}
\@writefile{tdo}{\contentsline {todo}{{try to get some results using markov chain implementation. Otherwise there's not much point in describing it ...}}{30}{section*.47}}
\pgfsyspdfmark {pgfid77}{9913630}{46661975}
\pgfsyspdfmark {pgfid78}{5539101}{44637174}
\pgfsyspdfmark {pgfid79}{9159964}{42168588}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Novel PPL inference techniques}{31}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:infEngines}{{5}{31}{Novel PPL inference techniques\relax }{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Preliminaries}{31}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Slice sampling}{31}{subsection.5.1.1}}
\@writefile{tdo}{\contentsline {todo}{{add basic description of slice sampling}}{31}{section*.48}}
\pgfsyspdfmark {pgfid82}{6571294}{12910183}
\pgfsyspdfmark {pgfid85}{33522973}{13692634}
\pgfsyspdfmark {pgfid86}{37143836}{12698608}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Basic PPL Construction}{31}{subsection.5.1.2}}
\@writefile{tdo}{\contentsline {todo}{{add basic description of lightweight style PPL construction}}{31}{section*.49}}
\pgfsyspdfmark {pgfid87}{6571294}{8126807}
\pgfsyspdfmark {pgfid90}{33522973}{9343448}
\pgfsyspdfmark {pgfid91}{37143836}{7915232}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Stochastic Python}{32}{section.5.2}}
\@writefile{tdo}{\contentsline {todo}{{add description of implementation, space permitting}}{32}{section*.50}}
\pgfsyspdfmark {pgfid92}{9913630}{44356953}
\pgfsyspdfmark {pgfid93}{5539101}{45340278}
\pgfsyspdfmark {pgfid94}{9159964}{43854732}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Slice sampling inference engine}{32}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Custom Slice Sampling and Metropolis on Tdf models}{32}{subsection.5.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Burn-in time for local metropolis-hastings and slice sampling, on the two continuous Tdf models, as the target neighbourhood varies.\relax }}{32}{figure.caption.51}}
\newlabel{fig:SliceMetCustPerf}{{5.1}{32}{Burn-in time for local metropolis-hastings and slice sampling, on the two continuous Tdf models, as the target neighbourhood varies.\relax \relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Burn-in time for slice samplin, when assuming an underlying Gaussian likelihood function which's mean we vary.\relax }}{33}{figure.caption.52}}
\newlabel{fig:SliceSampsMean}{{5.2}{33}{Burn-in time for slice samplin, when assuming an underlying Gaussian likelihood function which's mean we vary.\relax \relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Burn-in time for slice samplin, when assuming an underlying Gaussian likelihood function which's standard deviation we vary.\relax }}{33}{figure.caption.53}}
\newlabel{fig:SliceSampsStd}{{5.3}{33}{Burn-in time for slice samplin, when assuming an underlying Gaussian likelihood function which's standard deviation we vary.\relax \relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces The smallest Gaussian standard deviation considered in the experiment from Figure \ref  {fig}\relax }}{34}{figure.caption.54}}
\newlabel{fig:Gauss2}{{5.4}{34}{The smallest Gaussian standard deviation considered in the experiment from Figure \ref {fig}\relax \relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces The largest Gaussian standard deviation considered in the experiment from Figure \ref  {fig}\relax }}{34}{figure.caption.55}}
\newlabel{fig:Gauss20}{{5.5}{34}{The largest Gaussian standard deviation considered in the experiment from Figure \ref {fig}\relax \relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Sample evolution of the metropolis-hastings algorithm on the Tdf continuous model\relax }}{35}{figure.caption.56}}
\newlabel{fig:MetSampEvol}{{5.6}{35}{Sample evolution of the metropolis-hastings algorithm on the Tdf continuous model\relax \relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Sample evolution of the slice sampling algorithm on the Tdf continuous model\relax }}{35}{figure.caption.57}}
\newlabel{fig:SliceSampEvol}{{5.7}{35}{Sample evolution of the slice sampling algorithm on the Tdf continuous model\relax \relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Sample autocorrelation of the metropolis-hastings algorithm on the Tdf continuous model\relax }}{36}{figure.caption.58}}
\newlabel{fig:MetAutoCorr}{{5.8}{36}{Sample autocorrelation of the metropolis-hastings algorithm on the Tdf continuous model\relax \relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Sample autocorrelation of the slice sampling algorithm on the Tdf continuous model\relax }}{36}{figure.caption.59}}
\newlabel{fig:SliceAutoCorr}{{5.9}{36}{Sample autocorrelation of the slice sampling algorithm on the Tdf continuous model\relax \relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Empirical sample distribution of the metropolis-hastings algorithm on the Tdf continuous model\relax }}{37}{figure.caption.60}}
\newlabel{fig:MetSampDist}{{5.10}{37}{Empirical sample distribution of the metropolis-hastings algorithm on the Tdf continuous model\relax \relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Empirical sample distribution of the slice sampling algorithm on the Tdf continuous model\relax }}{37}{figure.caption.61}}
\newlabel{fig:SliceSampDist}{{5.11}{37}{Empirical sample distribution of the slice sampling algorithm on the Tdf continuous model\relax \relax }{figure.caption.61}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Generic, lightweight, slice sampling inference engine}{38}{subsection.5.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Slice sampling on Tdf model}{39}{section*.62}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Sample distribution from running custom, lightweight style, Metropolis-Hastings for 10 minutes on Tdf continuous model.\relax }}{39}{figure.caption.63}}
\newlabel{fig:MetLISampDist}{{5.12}{39}{Sample distribution from running custom, lightweight style, Metropolis-Hastings for 10 minutes on Tdf continuous model.\relax \relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Sample distribution from running Venture for 10 minutes on Tdf continuous model.\relax }}{39}{figure.caption.64}}
\newlabel{fig:VentureLISampDist}{{5.13}{39}{Sample distribution from running Venture for 10 minutes on Tdf continuous model.\relax \relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Sample distribution from running custom, lightweight style, slice sampling for 10 minutes on Tdf continuous model.\relax }}{40}{figure.caption.65}}
\newlabel{fig:SliceLISampDist}{{5.14}{40}{Sample distribution from running custom, lightweight style, slice sampling for 10 minutes on Tdf continuous model.\relax \relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Comparison of decreasing Kolmogorov-Smirnov differences between true and inferred posterior.\relax }}{41}{figure.caption.66}}
\newlabel{fig:TdfSliceLIComp}{{5.15}{41}{Comparison of decreasing Kolmogorov-Smirnov differences between true and inferred posterior.\relax \relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{Slice sampling on gaussian mean inference models}{41}{section*.67}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Analytically derived posterior for the NormalMean1 model.\relax }}{42}{figure.caption.68}}
\newlabel{fig:Normal1Post}{{5.16}{42}{Analytically derived posterior for the NormalMean1 model.\relax \relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Analytically derived posterior for the NormalMean2 model.\relax }}{42}{figure.caption.69}}
\newlabel{fig:Normal2Post}{{5.17}{42}{Analytically derived posterior for the NormalMean2 model.\relax \relax }{figure.caption.69}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Analytically derived posterior for the NormalMean3 model.\relax }}{43}{figure.caption.70}}
\newlabel{fig:Normal3Post}{{5.18}{43}{Analytically derived posterior for the NormalMean3 model.\relax \relax }{figure.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Runs generated by slice, metropolis and an equal mix of metropolis and slice on the 1 dimensional NormalMean1 model.\relax }}{44}{figure.caption.71}}
\newlabel{fig:Normal1Runs}{{5.19}{44}{Runs generated by slice, metropolis and an equal mix of metropolis and slice on the 1 dimensional NormalMean1 model.\relax \relax }{figure.caption.71}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Quartiles of the runs generated by slice, metropolis and an two different mixes of metropolis and slice on the 1 dimensional NormalMean1 model.\relax }}{44}{figure.caption.72}}
\newlabel{fig:Normal1Quarts}{{5.20}{44}{Quartiles of the runs generated by slice, metropolis and an two different mixes of metropolis and slice on the 1 dimensional NormalMean1 model.\relax \relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces Runs generated by slice, metropolis and an equal mix of metropolis and slice on the 2 dimensional NormalMean2 model.\relax }}{45}{figure.caption.73}}
\newlabel{fig:Normal2Runs}{{5.21}{45}{Runs generated by slice, metropolis and an equal mix of metropolis and slice on the 2 dimensional NormalMean2 model.\relax \relax }{figure.caption.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.22}{\ignorespaces Quartiles of the runs generated by slice, metropolis and an two different mixes of metropolis and slice on the 2 dimensional NormalMean2 model.\relax }}{45}{figure.caption.74}}
\newlabel{fig:Normal2Quarts}{{5.22}{45}{Quartiles of the runs generated by slice, metropolis and an two different mixes of metropolis and slice on the 2 dimensional NormalMean2 model.\relax \relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.23}{\ignorespaces Runs generated by slice, metropolis and an equal mix of metropolis and slice on the trans-dimensional NormalMean3 model.\relax }}{46}{figure.caption.75}}
\newlabel{fig:Normal4Runs}{{5.23}{46}{Runs generated by slice, metropolis and an equal mix of metropolis and slice on the trans-dimensional NormalMean3 model.\relax \relax }{figure.caption.75}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.24}{\ignorespaces Quartiles of the runs generated by slice, metropolis and an two different mixes of metropolis and slice on the trans-dimensional NormalMean3 model.\relax }}{46}{figure.caption.76}}
\newlabel{fig:Normal4Quarts}{{5.24}{46}{Quartiles of the runs generated by slice, metropolis and an two different mixes of metropolis and slice on the trans-dimensional NormalMean3 model.\relax \relax }{figure.caption.76}{}}
\@writefile{toc}{\contentsline {subsubsection}{Branching Model}{47}{section*.77}}
\@writefile{tdo}{\contentsline {todo}{{mention the discrepancy with the paper?}}{47}{section*.78}}
\pgfsyspdfmark {pgfid97}{17139390}{13046924}
\pgfsyspdfmark {pgfid100}{33522973}{13829375}
\pgfsyspdfmark {pgfid101}{37143836}{12835349}
\@writefile{lof}{\contentsline {figure}{\numberline {5.25}{\ignorespaces True posterior for the Branching Model\relax }}{48}{figure.caption.79}}
\newlabel{fig:BranchPost}{{5.25}{48}{True posterior for the Branching Model\relax \relax }{figure.caption.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.26}{\ignorespaces Runs generated by slice, metropolis and two mixtures of metropolis and slice on the Branching model.\relax }}{48}{figure.caption.80}}
\newlabel{fig:BranchRuns}{{5.26}{48}{Runs generated by slice, metropolis and two mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.27}{\ignorespaces Quartiles of the runs generated by slice, metropolis and two mixtures of metropolis and slice on the Branching model.\relax }}{49}{figure.caption.81}}
\newlabel{fig:BranchQuarts}{{5.27}{49}{Quartiles of the runs generated by slice, metropolis and two mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.81}{}}
\@writefile{tdo}{\contentsline {todo}{{talk about the continuous vs. discrete aspect and the domain in which we expect slice to be good}}{50}{section*.82}}
\pgfsyspdfmark {pgfid102}{19059130}{44695895}
\pgfsyspdfmark {pgfid103}{5539101}{44637174}
\pgfsyspdfmark {pgfid104}{9159964}{42168588}
\@writefile{lof}{\contentsline {figure}{\numberline {5.28}{\ignorespaces Runs generated by metropolis and two mixtures of metropolis and slice on the Branching model.\relax }}{50}{figure.caption.83}}
\newlabel{fig:BranchRunsSamps}{{5.28}{50}{Runs generated by metropolis and two mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.83}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.29}{\ignorespaces Quartiles of the runs generated by metropolis and two mixtures of metropolis and slice on the Branching model.\relax }}{51}{figure.caption.84}}
\newlabel{fig:BranchQuartsSamps}{{5.29}{51}{Quartiles of the runs generated by metropolis and two mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.84}{}}
\@writefile{toc}{\contentsline {subsubsection}{Trans-dimensional slice sampling}{51}{section*.85}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.30}{\ignorespaces Space of trace likelihoods if both variables are always sampled.\relax }}{52}{figure.caption.86}}
\newlabel{fig:BranchTraceLik}{{5.30}{52}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.31}{\ignorespaces Space of trace likelihoods implied by naive slice sampling.\relax }}{53}{figure.caption.87}}
\newlabel{fig:BranchWrongTraceLik}{{5.31}{53}{Space of trace likelihoods implied by naive slice sampling.\relax \relax }{figure.caption.87}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.32}{\ignorespaces Branching posterior implied by naive slice sampling.\relax }}{53}{figure.caption.88}}
\newlabel{fig:BranchWrongPost}{{5.32}{53}{Branching posterior implied by naive slice sampling.\relax \relax }{figure.caption.88}{}}
\@writefile{tdo}{\contentsline {todo}{{mention buggy metropolis version that also samples from this}}{53}{section*.89}}
\pgfsyspdfmark {pgfid107}{9139314}{9561816}
\pgfsyspdfmark {pgfid110}{33522973}{10835787}
\pgfsyspdfmark {pgfid111}{37143836}{9350241}
\@writefile{lof}{\contentsline {figure}{\numberline {5.33}{\ignorespaces Runs generated by metropolis, a 1:1 mixtures of metropolis and slice and the corrected slice on the NormalMean3 model.\relax }}{54}{figure.caption.90}}
\newlabel{fig:Normal4TDRuns}{{5.33}{54}{Runs generated by metropolis, a 1:1 mixtures of metropolis and slice and the corrected slice on the NormalMean3 model.\relax \relax }{figure.caption.90}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.34}{\ignorespaces Quartiles of the euns generated by metropolis, a 1:1 mixtures of metropolis and slice, the corrected slice and the naive slice algorithms on the NormalMean3 model.\relax }}{55}{figure.caption.91}}
\newlabel{fig:Normal4TDQuarts}{{5.34}{55}{Quartiles of the euns generated by metropolis, a 1:1 mixtures of metropolis and slice, the corrected slice and the naive slice algorithms on the NormalMean3 model.\relax \relax }{figure.caption.91}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.35}{\ignorespaces Runs generated by metropolis, a 1:1 mixtures of metropolis and slice, the corrected slice and the naive slice algorithms on the Branching model.\relax }}{55}{figure.caption.92}}
\newlabel{fig:BranchTDRuns}{{5.35}{55}{Runs generated by metropolis, a 1:1 mixtures of metropolis and slice, the corrected slice and the naive slice algorithms on the Branching model.\relax \relax }{figure.caption.92}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.36}{\ignorespaces Quartiles of the runs generated by metropolis, a 1:1 mixtures of metropolis and slice, the corrected slice and the naive slice algorithms on the Branching model.\relax }}{56}{figure.caption.93}}
\newlabel{fig:BranchTDQuarts}{{5.36}{56}{Quartiles of the runs generated by metropolis, a 1:1 mixtures of metropolis and slice, the corrected slice and the naive slice algorithms on the Branching model.\relax \relax }{figure.caption.93}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Quasi-Monte Carlo}{56}{section.5.4}}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Summary and Conclusions}{57}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
