\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{ppaml}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{ppaml}{{1}{1}{chapter.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Importance of Probabilistic Programming Languages}{1}{section.1.1}}
\newlabel{sect:importance}{{1.1}{1}{Importance of Probabilistic Programming Languages\relax }{section.1.1}{}}
\citation{goodman2013principles}
\citation{wingate2011nonstandard}
\citation{wood2014new}
\citation{stuhlmuller2012dynamic}
\citation{yeh2012synthesizing}
\citation{mansinghka2014venture}
\citation{yang2013incrementalizing}
\citation{goodman2013knowledge}
\citation{frank2012predicting}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Need for better inference}{2}{section.1.2}}
\newlabel{sect:betInf}{{1.2}{2}{Need for better inference\relax }{section.1.2}{}}
\@writefile{brf}{\backcite{goodman2013principles, wingate2011nonstandard, wood2014new}{{2}{1.2}{section.1.2}}}
\@writefile{brf}{\backcite{stuhlmuller2012dynamic, yeh2012synthesizing}{{2}{1.2}{section.1.2}}}
\@writefile{brf}{\backcite{mansinghka2014venture, yang2013incrementalizing}{{2}{1.2}{section.1.2}}}
\@writefile{brf}{\backcite{goodman2013knowledge, frank2012predicting}{{2}{1.2}{section.1.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Approach and Roadmap}{2}{section.1.3}}
\citation{stocPy}
\@writefile{brf}{\backcite{stocPy}{{3}{1.3}{section.1.3}}}
\citation{bugsOverview}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Comparing Venture and OpenBUGS}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:perfComp}{{2}{5}{Comparing Venture and OpenBUGS\relax }{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Motivation}{5}{section.2.1}}
\citation{lunn2009bugs}
\citation{mansinghka2014venture}
\citation{roy2008stochastic}
\citation{probMods}
\citation{gerstenberg2012ping}
\citation{mansinghka2009natively}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Preliminaries}{6}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}OpenBUGS}{6}{subsection.2.2.1}}
\@writefile{brf}{\backcite{bugsOverview}{{6}{2.2.1}{subsection.2.2.1}}}
\@writefile{brf}{\backcite{lunn2009bugs}{{6}{2.2.1}{subsection.2.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Venture}{6}{subsection.2.2.2}}
\@writefile{brf}{\backcite{mansinghka2014venture}{{6}{2.2.2}{subsection.2.2.2}}}
\@writefile{brf}{\backcite{roy2008stochastic}{{6}{2.2.2}{subsection.2.2.2}}}
\@writefile{brf}{\backcite{probMods, gerstenberg2012ping}{{7}{2.2.2}{subsection.2.2.2}}}
\@writefile{brf}{\backcite{mansinghka2009natively}{{7}{2.2.2}{subsection.2.2.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Number of MCMC steps}{7}{subsection.2.2.3}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Strategies for extracting S samples from a model with V unconditioned variables\relax }}{7}{table.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:noSteps}{{2.1}{7}{Strategies for extracting S samples from a model with V unconditioned variables\relax \relax }{table.caption.2}{}}
\citation{TdfBugsRepo}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Empirical results}{8}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Tdf model description}{8}{subsection.2.3.1}}
\newlabel{sect:tdfDesc}{{2.3.1}{8}{Tdf model description\relax }{subsection.2.3.1}{}}
\@writefile{brf}{\backcite{TdfBugsRepo}{{8}{2.3.1}{subsection.2.3.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Tdf model true posteriors}{8}{subsection.2.3.2}}
\newlabel{sect:truePost}{{2.3.2}{8}{Tdf model true posteriors\relax }{subsection.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces True posterior distributions for the 3 Tdf models.\relax }}{9}{figure.caption.3}}
\newlabel{fig:tdfPosts}{{2.1}{9}{True posterior distributions for the 3 Tdf models.\relax \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Tdf model results}{9}{subsection.2.3.3}}
\newlabel{fig:tdfCourseDiscSamp}{{2.2a}{10}{Distributions obtained by the two PPLs on the course discrete model.\relax \relax }{figure.caption.4}{}}
\newlabel{sub@fig:tdfCourseDiscSamp}{{a}{10}{Distributions obtained by the two PPLs on the course discrete model.\relax \relax }{figure.caption.4}{}}
\newlabel{fig:tdfCourseDiscConv}{{2.2b}{10}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.4}{}}
\newlabel{sub@fig:tdfCourseDiscConv}{{b}{10}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Performance of the Tdf course discrete model\relax }}{10}{figure.caption.4}}
\citation{lunn2000winbugs}
\citation{keith2008generalized}
\citation{webChurch}
\newlabel{fig:tdfFineDiscSamp}{{2.3a}{11}{Distributions obtained by the two PPLs on the fine discrete model.\relax \relax }{figure.caption.5}{}}
\newlabel{sub@fig:tdfFineDiscSamp}{{a}{11}{Distributions obtained by the two PPLs on the fine discrete model.\relax \relax }{figure.caption.5}{}}
\newlabel{fig:tdfFineDiscConv}{{2.3b}{11}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.5}{}}
\newlabel{sub@fig:tdfFineDiscConv}{{b}{11}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Performance of the Tdf fine discrete model\relax }}{11}{figure.caption.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Analysis of Venture's performance}{11}{section.2.4}}
\@writefile{brf}{\backcite{lunn2000winbugs, keith2008generalized}{{11}{2.4}{figure.caption.7}}}
\newlabel{fig:tdfContSamp}{{2.4a}{12}{Distributions obtained by the two PPLs on the continuous model.\relax \relax }{figure.caption.6}{}}
\newlabel{sub@fig:tdfContSamp}{{a}{12}{Distributions obtained by the two PPLs on the continuous model.\relax \relax }{figure.caption.6}{}}
\newlabel{fig:tdfContConv}{{2.4b}{12}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KS difference achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.6}{}}
\newlabel{sub@fig:tdfContConv}{{b}{12}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KS difference achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Performance of the Tdf continuous model\relax }}{12}{figure.caption.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Webchurch's performance}{12}{subsection.2.4.1}}
\@writefile{brf}{\backcite{webChurch}{{12}{2.4.1}{subsection.2.4.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Number and size of identical sample runs generated by the two PPLs on the continuous model.\relax }}{13}{figure.caption.7}}
\newlabel{fig:tdfContRun}{{2.5}{13}{Number and size of identical sample runs generated by the two PPLs on the continuous model.\relax \relax }{figure.caption.7}{}}
\citation{kullback1951information}
\citation{massey1951kolmogorov}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Partitioned Priors}{15}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:partPriors}{{3}{15}{Partitioned Priors\relax }{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Preliminaries}{15}{section.3.1}}
\citation{metropolis1953equation}
\citation{hastings1970monte}
\citation{neal1993probabilistic}
\@writefile{brf}{\backcite{kullback1951information}{{16}{3.1}{section.3.1}}}
\@writefile{brf}{\backcite{massey1951kolmogorov}{{16}{3.1}{section.3.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Metropolis-Hastings}{16}{subsection.3.1.1}}
\newlabel{sect:MH}{{3.1.1}{16}{Metropolis-Hastings\relax }{subsection.3.1.1}{}}
\@writefile{brf}{\backcite{metropolis1953equation, hastings1970monte}{{16}{3.1.1}{subsection.3.1.1}}}
\@writefile{brf}{\backcite{neal1993probabilistic}{{16}{3.1.1}{subsection.3.1.1}}}
\citation{mackay2003information}
\citation{neal1993probabilistic}
\@writefile{brf}{\backcite{mackay2003information, neal1993probabilistic}{{17}{3.1.1}{subsection.3.1.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Expected number of iterations to a neighbourhood of the mode}{17}{subsection.3.1.2}}
\newlabel{section:sampsToMode}{{3.1.2}{17}{Expected number of iterations to a neighbourhood of the mode\relax }{subsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Mixing properties around the mode}{18}{subsection.3.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Sum of uniforms}{18}{section.3.2}}
\newlabel{sect:sumUnif}{{3.2}{18}{Sum of uniforms\relax }{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Distribution induced by partitioning the prior (uniform-continuous 2 100) into (uniform-continuous 2 95) + (uniform-continuous 0 2) (uniform-continuous 0 1).\relax }}{19}{figure.caption.8}}
\newlabel{fig:1295Prior}{{3.1}{19}{Distribution induced by partitioning the prior (uniform-continuous 2 100) into (uniform-continuous 2 95) + (uniform-continuous 0 2) (uniform-continuous 0 1).\relax \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Finding a good sum decomposition}{19}{subsection.3.2.1}}
\newlabel{sect:goodSum}{{3.2.1}{19}{Finding a good sum decomposition\relax }{subsection.3.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Expected number of steps to mode neighbourhoods on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax }}{20}{table.caption.9}}
\newlabel{tab:bestParts}{{3.1}{20}{Expected number of steps to mode neighbourhoods on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax \relax }{table.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Average distance travelled around the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax }}{21}{table.caption.10}}
\newlabel{tab:partMix}{{3.2}{21}{Average distance travelled around the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax \relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Evaluating the (1,2,95) sum decomposition}{21}{subsection.3.2.2}}
\newlabel{sect:1295Eval}{{3.2.2}{21}{Evaluating the (1,2,95) sum decomposition\relax }{subsection.3.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{21}{figure.caption.11}}
\newlabel{fig:tdfPSampEvol}{{3.2}{21}{Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{22}{figure.caption.12}}
\newlabel{fig:tdfPAutoCorr}{{3.3}{22}{Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{22}{figure.caption.13}}
\newlabel{fig:tdfPDist}{{3.4}{22}{Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Tdf21 model}{22}{section*.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The true posteriors of the Tdf continuous and the Tdf21 continuous models.\relax }}{23}{figure.caption.15}}
\newlabel{fig:tdfPPost}{{3.5}{23}{The true posteriors of the Tdf continuous and the Tdf21 continuous models.\relax \relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The true log-likelihoods of the Tdf continuous and the Tdf21 continuous models.\relax }}{23}{figure.caption.16}}
\newlabel{fig:tdfPLL}{{3.6}{23}{The true log-likelihoods of the Tdf continuous and the Tdf21 continuous models.\relax \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluating the decomposition on the Tdf21 model}{23}{section*.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{24}{figure.caption.18}}
\newlabel{fig:tdf21PSampEvol}{{3.7}{24}{Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{24}{figure.caption.19}}
\newlabel{fig:tdf21PAutoCorr}{{3.8}{24}{Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Bit decomposition}{24}{section.3.3}}
\newlabel{sect:bitDecomp}{{3.3}{24}{Bit decomposition\relax }{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{25}{figure.caption.20}}
\newlabel{fig:tdf21PSampDist}{{3.9}{25}{Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Definition}{25}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Evaluation on Tdf and Tdf21}{25}{subsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Sample distributions for an unpartitioned and a 3 bit decomposition prior, over 10,000 samples on the Tdf continuous model.\relax }}{26}{figure.caption.21}}
\newlabel{fig:tdfPSampDist}{{3.10}{26}{Sample distributions for an unpartitioned and a 3 bit decomposition prior, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Sample distributions for an unpartitioned and a 3 bit decomposition prios, over 10,000 samples on the Tdf21 model.\relax }}{26}{figure.caption.22}}
\newlabel{fig:tdf21PSampDist}{{3.11}{26}{Sample distributions for an unpartitioned and a 3 bit decomposition prios, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Expected number of steps to neighbourhoods of the mode on the Tdf and Tdf21 continuous models for an unpartitioned prior, the (1,2,95) sum decomposition and 2 bit decompositions.\relax }}{27}{table.caption.23}}
\newlabel{tab:bestParts}{{3.3}{27}{Expected number of steps to neighbourhoods of the mode on the Tdf and Tdf21 continuous models for an unpartitioned prior, the (1,2,95) sum decomposition and 2 bit decompositions.\relax \relax }{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Getting stuck on a bad sample}{27}{subsection.3.3.3}}
\newlabel{sect:stuckSamples}{{3.3.3}{27}{Getting stuck on a bad sample\relax }{subsection.3.3.3}{}}
\citation{mackay2003information}
\@writefile{brf}{\backcite{mackay2003information}{{29}{3.3.3}{subsection.3.3.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Mixtures of shifted bit decompositions}{29}{subsection.3.3.4}}
\newlabel{sect:shifts}{{3.3.4}{29}{Mixtures of shifted bit decompositions\relax }{subsection.3.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Avoiding getting stuck}{29}{section*.24}}
\newlabel{sect:stuckMath}{{3.3.4}{29}{Avoiding getting stuck\relax }{section*.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{Empirical performance}{32}{section*.25}}
\newlabel{fig:allMaxShifts}{{3.12a}{32}{Maximum sized shifts.\relax \relax }{figure.caption.26}{}}
\newlabel{sub@fig:allMaxShifts}{{a}{32}{Maximum sized shifts.\relax \relax }{figure.caption.26}{}}
\newlabel{fig:allMinShifts}{{3.12b}{32}{Minimum sized shifts.\relax \relax }{figure.caption.26}{}}
\newlabel{sub@fig:allMinShifts}{{b}{32}{Minimum sized shifts.\relax \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Time to 0.001 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax }}{32}{figure.caption.26}}
\newlabel{fig:allShifts}{{3.12}{32}{Time to 0.001 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax }}{33}{figure.caption.27}}
\newlabel{fig:AllShiftsMax001}{{3.13}{33}{Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax \relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depth using a small number of shifts.\relax }}{33}{figure.caption.28}}
\newlabel{fig:fewShifts}{{3.14}{33}{Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depth using a small number of shifts.\relax \relax }{figure.caption.28}{}}
\citation{neal2003slice}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Novel PPL inference techniques}{35}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:infEngines}{{4}{35}{Novel PPL inference techniques\relax }{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preliminaries}{35}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Slice sampling}{35}{subsection.4.1.1}}
\newlabel{sect:sliceBack}{{4.1.1}{35}{Slice sampling\relax }{subsection.4.1.1}{}}
\@writefile{brf}{\backcite{neal2003slice}{{35}{4.1.1}{subsection.4.1.1}}}
\citation{neal2003slice}
\citation{mackay2003information}
\citation{wingate2011lightweight}
\citation{wingate2011lightweight}
\citation{green2009reversible}
\citation{stocPy}
\@writefile{brf}{\backcite{neal2003slice, mackay2003information}{{37}{4.1.1}{subsection.4.1.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Basic PPL Construction}{37}{subsection.4.1.2}}
\newlabel{pplBack}{{4.1.2}{37}{Basic PPL Construction\relax }{subsection.4.1.2}{}}
\@writefile{brf}{\backcite{wingate2011lightweight}{{37}{4.1.2}{subsection.4.1.2}}}
\@writefile{brf}{\backcite{wingate2011lightweight}{{37}{4.1.2}{subsection.4.1.2}}}
\@writefile{brf}{\backcite{green2009reversible}{{37}{4.1.2}{subsection.4.1.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Stochastic Python}{37}{section.4.2}}
\newlabel{sect:StocPy}{{4.2}{37}{Stochastic Python\relax }{section.4.2}{}}
\@writefile{brf}{\backcite{stocPy}{{37}{4.2}{section.4.2}}}
\citation{wingate2011lightweight}
\@writefile{brf}{\backcite{wingate2011lightweight}{{38}{4.2}{section.4.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Slice sampling inference engine}{38}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Custom Slice Sampling and Metropolis on Tdf models}{38}{subsection.4.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Burn-in time for local metropolis-hastings and slice sampling, on the two continuous Tdf models, as the target neighbourhood varies.\relax }}{39}{figure.caption.29}}
\newlabel{fig:SliceMetCustPerf}{{4.1}{39}{Burn-in time for local metropolis-hastings and slice sampling, on the two continuous Tdf models, as the target neighbourhood varies.\relax \relax }{figure.caption.29}{}}
\citation{wingate2011lightweight}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Average burn-in time for slice sampling guided by a Gaussian likelihood of varying mean and standard deviation\relax }}{40}{figure.caption.30}}
\newlabel{fig:sliceGaussLik}{{4.2}{40}{Average burn-in time for slice sampling guided by a Gaussian likelihood of varying mean and standard deviation\relax \relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The smallest and largest Gaussian standard deviation considered in Figure \ref  {fig:sliceGaussLik}\relax }}{40}{figure.caption.31}}
\newlabel{fig:gaussStdDev}{{4.3}{40}{The smallest and largest Gaussian standard deviation considered in Figure \ref {fig:sliceGaussLik}\relax \relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Empirical sample distribution of local metropolis and slice sampling on the Tdf continuous model\relax }}{40}{figure.caption.34}}
\newlabel{fig:custSampDist}{{4.6}{40}{Empirical sample distribution of local metropolis and slice sampling on the Tdf continuous model\relax \relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Sample evolution of local metropolis and slice sampling on the Tdf continuous model\relax }}{41}{figure.caption.32}}
\newlabel{fig:custSampEvol}{{4.4}{41}{Sample evolution of local metropolis and slice sampling on the Tdf continuous model\relax \relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Sample autocorrelation of local metropolis and slice sampling on the Tdf continuous model\relax }}{41}{figure.caption.33}}
\newlabel{fig:custAutoCorr}{{4.5}{41}{Sample autocorrelation of local metropolis and slice sampling on the Tdf continuous model\relax \relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Generic, lightweight, slice sampling inference engine}{41}{subsection.4.3.2}}
\@writefile{brf}{\backcite{wingate2011lightweight}{{41}{4.3.2}{subsection.4.3.2}}}
\@writefile{toc}{\contentsline {subsubsection}{Slice sampling on the Tdf model}{42}{section*.35}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Sample distribution from running Venture and stochastic python versions of metropolis and slice sampling for 10 minutes on the Tdf continuous model.\relax }}{42}{figure.caption.36}}
\newlabel{fig:tdfSampDists}{{4.7}{42}{Sample distribution from running Venture and stochastic python versions of metropolis and slice sampling for 10 minutes on the Tdf continuous model.\relax \relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Comparison of Kolmogorov-Smirnov differences between true and inferred posteriors.\relax }}{43}{figure.caption.37}}
\newlabel{fig:TdfSliceLIComp}{{4.8}{43}{Comparison of Kolmogorov-Smirnov differences between true and inferred posteriors.\relax \relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{Slice sampling on gaussian mean inference models}{43}{section*.38}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Analytically derived posteriors of the NormalMean1, NormalMean2 and NormalMean3 models.\relax }}{44}{figure.caption.39}}
\newlabel{fig:tdfSampDists}{{4.9}{44}{Analytically derived posteriors of the NormalMean1, NormalMean2 and NormalMean3 models.\relax \relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 1 dimensional NormalMean1 model.\relax }}{44}{figure.caption.40}}
\newlabel{fig:normal1Perf}{{4.10}{44}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 1 dimensional NormalMean1 model.\relax \relax }{figure.caption.40}{}}
\citation{wood2014new}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 2 dimensional NormalMean2 model.\relax }}{45}{figure.caption.41}}
\newlabel{fig:normal2Perf}{{4.11}{45}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 2 dimensional NormalMean2 model.\relax \relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the trans-dimensional NormalMean3 model.\relax }}{45}{figure.caption.42}}
\newlabel{fig:normal4Perf}{{4.12}{45}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the trans-dimensional NormalMean3 model.\relax \relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{Branching Model}{46}{section*.43}}
\newlabel{sect:branching}{{4.3.2}{46}{Branching Model\relax }{section*.43}{}}
\@writefile{brf}{\backcite{wood2014new}{{46}{4.3.2}{section*.43}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces True posterior for the Branching Model\relax }}{46}{figure.caption.44}}
\newlabel{fig:BranchPost}{{4.13}{46}{True posterior for the Branching Model\relax \relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax }}{47}{figure.caption.45}}
\newlabel{fig:branchPerf}{{4.14}{47}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax }}{48}{figure.caption.46}}
\newlabel{fig:branchPerfSamps}{{4.15}{48}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsubsection}{Trans-dimensional slice sampling}{48}{section*.47}}
\newlabel{sect:tdSlice}{{4.3.2}{48}{Trans-dimensional slice sampling\relax }{section*.47}{}}
\newlabel{fig:branchTraceLik}{{4.16a}{49}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.48}{}}
\newlabel{sub@fig:branchTraceLik}{{a}{49}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.48}{}}
\newlabel{fig:branchPost}{{4.16b}{49}{True posterior of Branching model.\relax \relax }{figure.caption.48}{}}
\newlabel{sub@fig:branchPost}{{b}{49}{True posterior of Branching model.\relax \relax }{figure.caption.48}{}}
\newlabel{fig:branchWrongTraceLik}{{4.16c}{49}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.49}{}}
\newlabel{sub@fig:branchWrongTraceLik}{{c}{49}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.49}{}}
\newlabel{fig:branchWrongPost}{{4.16d}{49}{Space of trace likelihoods implied by naive slice sampling.\relax \relax }{figure.caption.49}{}}
\newlabel{sub@fig:branchWrongPost}{{d}{49}{Space of trace likelihoods implied by naive slice sampling.\relax \relax }{figure.caption.49}{}}
\citation{robert2004monte}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the modified and the naive slice algorithms on the NormalMean3 model.\relax }}{50}{figure.caption.50}}
\newlabel{fig:normal4TD}{{4.16}{50}{Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the modified and the naive slice algorithms on the NormalMean3 model.\relax \relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the corrected slice and the naive slice algorithms on the Branching model.\relax }}{50}{figure.caption.51}}
\newlabel{fig:branchTD}{{4.17}{50}{Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the corrected slice and the naive slice algorithms on the Branching model.\relax \relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Quasi-Monte Carlo}{51}{section.4.4}}
\@writefile{brf}{\backcite{robert2004monte}{{51}{4.4}{section.4.4}}}
\citation{jones1989probabilistic}
\citation{ppw}
\citation{kimmig2011implementation}
\citation{de2008probabilistic}
\citation{sato1997prism}
\citation{poole2008independent}
\citation{goodman2008church}
\citation{mansinghka2014venture}
\citation{wood2014new}
\citation{abelson1991revised}
\citation{kiselyov2009embedded}
\citation{lunn2009bugs}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Related Work}{53}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:relWork}{{5}{53}{Related Work\relax }{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Probabilistic Programming Languages}{53}{section.5.1}}
\newlabel{sect:ppl}{{5.1}{53}{Probabilistic Programming Languages\relax }{section.5.1}{}}
\@writefile{brf}{\backcite{jones1989probabilistic}{{53}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{ppw}{{53}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{kimmig2011implementation, de2008probabilistic, sato1997prism, poole2008independent}{{53}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{goodman2008church, mansinghka2014venture, wood2014new}{{53}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{abelson1991revised}{{53}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{kiselyov2009embedded}{{53}{5.1}{section.5.1}}}
\citation{lunn2009bugs}
\citation{richardson2006markov}
\citation{mccallum2009factorie}
\citation{stan-software:2014}
\citation{minkainfer}
\citation{milch20071}
\citation{pfeffer2001ibal}
\citation{pfeffer2009figaro}
\citation{goodman2008church}
\citation{stuhlmuller2012dynamic}
\citation{wingate2011nonstandard}
\citation{yang2013incrementalizing}
\@writefile{brf}{\backcite{lunn2009bugs}{{54}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{lunn2009bugs, richardson2006markov, mccallum2009factorie, stan-software:2014, minkainfer}{{54}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{milch20071, pfeffer2001ibal, pfeffer2009figaro, goodman2008church}{{54}{5.1}{section.5.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Speeding up inference}{54}{section.5.2}}
\@writefile{brf}{\backcite{stuhlmuller2012dynamic}{{54}{5.2}{section.5.2}}}
\@writefile{brf}{\backcite{wingate2011nonstandard}{{54}{5.2}{section.5.2}}}
\citation{wood2014new}
\citation{yeh2012synthesizing}
\@writefile{brf}{\backcite{yang2013incrementalizing}{{55}{5.2}{section.5.2}}}
\@writefile{brf}{\backcite{wood2014new}{{55}{5.2}{section.5.2}}}
\@writefile{brf}{\backcite{yeh2012synthesizing}{{55}{5.2}{section.5.2}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Summary and Conclusions}{57}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conc}{{6}{57}{Summary and Conclusions\relax }{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Overview}{57}{section.6.1}}
\bibstyle{plain}
\bibdata{dissertation}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Future Directions}{58}{section.6.2}}
\bibcite{ppw}{1}
\bibcite{abelson1991revised}{2}
\bibcite{ppaml}{3}
\bibcite{de2008probabilistic}{4}
\bibcite{frank2012predicting}{5}
\bibcite{gerstenberg2012ping}{6}
\bibcite{probMods}{7}
\bibcite{webChurch}{8}
\bibcite{goodman2013principles}{9}
\bibcite{goodman2008church}{10}
\bibcite{goodman2013knowledge}{11}
\bibcite{green2009reversible}{12}
\bibcite{hastings1970monte}{13}
\bibcite{jones1989probabilistic}{14}
\bibcite{keith2008generalized}{15}
\bibcite{kimmig2011implementation}{16}
\bibcite{kiselyov2009embedded}{17}
\bibcite{kullback1951information}{18}
\bibcite{lunn2009bugs}{19}
\bibcite{lunn2000winbugs}{20}
\bibcite{mackay2003information}{21}
\bibcite{mansinghka2014venture}{22}
\bibcite{mansinghka2009natively}{23}
\bibcite{massey1951kolmogorov}{24}
\bibcite{mccallum2009factorie}{25}
\bibcite{metropolis1953equation}{26}
\bibcite{milch20071}{27}
\bibcite{minkainfer}{28}
\bibcite{neal1993probabilistic}{29}
\bibcite{neal2003slice}{30}
\bibcite{bugsOverview}{31}
\bibcite{pfeffer2001ibal}{32}
\bibcite{pfeffer2009figaro}{33}
\bibcite{poole2008independent}{34}
\bibcite{stocPy}{35}
\bibcite{TdfBugsRepo}{36}
\bibcite{richardson2006markov}{37}
\bibcite{robert2004monte}{38}
\bibcite{roy2008stochastic}{39}
\bibcite{sato1997prism}{40}
\bibcite{stan-software:2014}{41}
\bibcite{stuhlmuller2012dynamic}{42}
\bibcite{wingate2011nonstandard}{43}
\bibcite{wingate2011lightweight}{44}
\bibcite{wood2014new}{45}
\bibcite{yang2013incrementalizing}{46}
\bibcite{yeh2012synthesizing}{47}
