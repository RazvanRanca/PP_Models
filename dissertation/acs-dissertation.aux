\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{1}{section.1.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Comparing Venture and OpenBUGS}{5}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Motivation}{5}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Preliminaries}{6}{section.3.2}}
\@writefile{tdo}{\contentsline {todo}{{Add background info on Venture and OpenBUGS}}{6}{section*.4}}
\pgfsyspdfmark {pgfid1}{9913630}{40713507}
\pgfsyspdfmark {pgfid2}{5539101}{41495958}
\pgfsyspdfmark {pgfid3}{9159964}{40501932}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Number of MCMC steps}{6}{subsection.3.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Strategies for extracting S samples from a model with V unconditioned variables\relax }}{6}{table.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:noSteps}{{3.1}{6}{Strategies for extracting S samples from a model with V unconditioned variables\relax \relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Empirical results}{6}{section.3.3}}
\@writefile{tdo}{\contentsline {todo}{{Maybe also evaluate one model that's not from the OpenBUGS repository, since BUGS might be unreasonably optimized on its own models.}}{7}{section*.6}}
\pgfsyspdfmark {pgfid6}{9284914}{46661975}
\pgfsyspdfmark {pgfid9}{33522973}{43711464}
\pgfsyspdfmark {pgfid10}{37143836}{40317168}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Tdf model description}{7}{subsection.3.3.1}}
\@writefile{tdo}{\contentsline {todo}{{add model pseudocode}}{7}{section*.7}}
\pgfsyspdfmark {pgfid11}{13014102}{32768759}
\pgfsyspdfmark {pgfid14}{33522973}{33059690}
\pgfsyspdfmark {pgfid15}{37143836}{32557184}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Tdf model true posteriors}{7}{subsection.3.3.2}}
\newlabel{sect:truePost}{{3.3.2}{7}{Tdf model true posteriors\relax }{subsection.3.3.2}{}}
\@writefile{tdo}{\contentsline {todo}{Figure: {Add formula used to derive posterior, as in the log}}{7}{subsection.3.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces True posterior distributions for the 3 Tdf models.\relax }}{8}{figure.caption.8}}
\newlabel{fig:tdfPosts}{{3.1}{8}{True posterior distributions for the 3 Tdf models.\relax \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Tdf model results}{8}{subsection.3.3.3}}
\@writefile{tdo}{\contentsline {todo}{{Add KL and KS difference results for these distributions}}{8}{section*.9}}
\pgfsyspdfmark {pgfid17}{9913630}{33036598}
\pgfsyspdfmark {pgfid18}{5539101}{34253239}
\pgfsyspdfmark {pgfid19}{9159964}{32825023}
\newlabel{fig:tdfCourseDiscSamp}{{3.2a}{8}{Distributions obtained by the two PPLs on the course discrete model.\relax \relax }{figure.caption.10}{}}
\newlabel{sub@fig:tdfCourseDiscSamp}{{a}{8}{Distributions obtained by the two PPLs on the course discrete model.\relax \relax }{figure.caption.10}{}}
\newlabel{fig:tdfCourseDiscConv}{{3.2b}{8}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.10}{}}
\newlabel{sub@fig:tdfCourseDiscConv}{{b}{8}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Performance of the Tdf course discrete model\relax }}{8}{figure.caption.10}}
\@writefile{tdo}{\contentsline {todo}{{Maybe do more runs and plot quartiles}}{8}{section*.11}}
\pgfsyspdfmark {pgfid22}{9913630}{8126807}
\pgfsyspdfmark {pgfid23}{5539101}{8909258}
\pgfsyspdfmark {pgfid24}{9159964}{7915232}
\newlabel{fig:tdfFineDiscSamp}{{3.3a}{9}{Distributions obtained by the two PPLs on the fine discrete model.\relax \relax }{figure.caption.12}{}}
\newlabel{sub@fig:tdfFineDiscSamp}{{a}{9}{Distributions obtained by the two PPLs on the fine discrete model.\relax \relax }{figure.caption.12}{}}
\newlabel{fig:tdfFineDiscConv}{{3.3b}{9}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.12}{}}
\newlabel{sub@fig:tdfFineDiscConv}{{b}{9}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KL divergence achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Performance of the Tdf fine discrete model\relax }}{9}{figure.caption.12}}
\newlabel{fig:tdfContSamp}{{3.4a}{10}{Distributions obtained by the two PPLs on the continuous model.\relax \relax }{figure.caption.13}{}}
\newlabel{sub@fig:tdfContSamp}{{a}{10}{Distributions obtained by the two PPLs on the continuous model.\relax \relax }{figure.caption.13}{}}
\newlabel{fig:tdfContConv}{{3.4b}{10}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KS difference achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.13}{}}
\newlabel{sub@fig:tdfContConv}{{b}{10}{Rate of convergence of the two engines as the number of samples increases (first 1,000 samples are discarded as burn-in). The black line shows the KS difference achieved by Venture after 101,000 inference steps.\relax \relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Performance of the Tdf continuous model\relax }}{10}{figure.caption.13}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Analysis of Venture's performance}{10}{section.3.4}}
\@writefile{tdo}{\contentsline {todo}{{saw this mentioned in a paper, need to find direct source or remove}}{10}{section*.15}}
\pgfsyspdfmark {pgfid27}{29584909}{10092887}
\pgfsyspdfmark {pgfid28}{5539101}{11309528}
\pgfsyspdfmark {pgfid29}{9159964}{9881312}
\@writefile{tdo}{\contentsline {todo}{{Decide is there's anything worth reporting from the performance tests done on Venture. Log dates: 2014.02.19 and 2014.02.20}}{10}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Number and size of identical sample runs generated by the two PPLs on the continuous model.\relax }}{11}{figure.caption.14}}
\newlabel{fig:tdfContRun}{{3.5}{11}{Number and size of identical sample runs generated by the two PPLs on the continuous model.\relax \relax }{figure.caption.14}{}}
\pgfsyspdfmark {pgfid32}{6571294}{26078691}
\pgfsyspdfmark {pgfid35}{33522973}{23619700}
\pgfsyspdfmark {pgfid36}{37143836}{20716924}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Webchurch's performance}{11}{subsection.3.4.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Partitioned Priors}{13}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\contentsline {todo}{{say something about proposal kernels vs. sampling from prior?}}{13}{section*.17}}
\pgfsyspdfmark {pgfid37}{20392578}{28446662}
\pgfsyspdfmark {pgfid40}{33522973}{29720633}
\pgfsyspdfmark {pgfid41}{37143836}{28235087}
\@writefile{tdo}{\contentsline {todo}{{not sure if this makes much sense. Need to research it or remove}}{13}{section*.18}}
\pgfsyspdfmark {pgfid42}{22024914}{19070784}
\pgfsyspdfmark {pgfid45}{33522973}{20287425}
\pgfsyspdfmark {pgfid46}{37143836}{18859209}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preliminaries}{13}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Local Metropolis-Hastings}{14}{subsection.4.1.1}}
\@writefile{tdo}{\contentsline {todo}{{add basic explanation}}{14}{section*.19}}
\pgfsyspdfmark {pgfid47}{9913630}{41352793}
\pgfsyspdfmark {pgfid48}{5539101}{41643724}
\pgfsyspdfmark {pgfid49}{9159964}{41141218}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Expected number of iterations to a neighbourhood of the mode}{14}{subsection.4.1.2}}
\newlabel{section:sampsToMode}{{4.1.2}{14}{Expected number of iterations to a neighbourhood of the mode\relax }{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Mixing properties around the mode}{14}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Sum of uniforms}{15}{section.4.2}}
\newlabel{sect:sumUnif}{{4.2}{15}{Sum of uniforms\relax }{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Distribution induced by partitioning the prior (uniform-continuous 2 100) into (uniform-continuous 2 95) + (uniform-continuous 0 2) (uniform-continuous 0 1).\relax }}{15}{figure.caption.20}}
\newlabel{fig:1295Prior}{{4.1}{15}{Distribution induced by partitioning the prior (uniform-continuous 2 100) into (uniform-continuous 2 95) + (uniform-continuous 0 2) (uniform-continuous 0 1).\relax \relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Finding a good sum decomposition}{16}{subsection.4.2.1}}
\newlabel{sect:goodSum}{{4.2.1}{16}{Finding a good sum decomposition\relax }{subsection.4.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Expected number of steps to mode neighbourhoods on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax }}{16}{table.caption.21}}
\newlabel{tab:bestParts}{{4.1}{16}{Expected number of steps to mode neighbourhoods on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax \relax }{table.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Average distance travelled around the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax }}{17}{table.caption.22}}
\newlabel{tab:bestParts}{{4.2}{17}{Average distance travelled around the mode on the Tdf continuous model for an unpartitioned prior and some of the best sum decomposition priors.\relax \relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Evaluating the (1,2,95) sum decomposition}{17}{subsection.4.2.2}}
\newlabel{sect:1295Eval}{{4.2.2}{17}{Evaluating the (1,2,95) sum decomposition\relax }{subsection.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{18}{figure.caption.23}}
\newlabel{fig:tdfPSampEvol}{{4.2}{18}{Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{18}{figure.caption.24}}
\newlabel{fig:tdfPAutoCorr}{{4.3}{18}{Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Tdf21 model}{18}{section*.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax }}{19}{figure.caption.25}}
\newlabel{fig:tdfPDist}{{4.4}{19}{Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The true posteriors of the Tdf continuous and the Tdf21 continuous models.\relax }}{19}{figure.caption.27}}
\newlabel{fig:tdfPPost}{{4.5}{19}{The true posteriors of the Tdf continuous and the Tdf21 continuous models.\relax \relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The true log-likelihoods of the Tdf continuous and the Tdf21 continuous models.\relax }}{20}{figure.caption.28}}
\newlabel{fig:tdfPLL}{{4.6}{20}{The true log-likelihoods of the Tdf continuous and the Tdf21 continuous models.\relax \relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluating the decomposition on the Tdf21 model}{20}{section*.29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{20}{figure.caption.30}}
\newlabel{fig:tdf21PSampEvol}{{4.7}{20}{Sample evolutions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{21}{figure.caption.31}}
\newlabel{fig:tdf21PAutoCorr}{{4.8}{21}{Sample autocorrelations for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax }}{21}{figure.caption.32}}
\newlabel{fig:tdf21PSampDist}{{4.9}{21}{Sample distributions for the unpartitioned and the (1, 2, 95) partitioned priors, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Bit decomposition}{21}{section.4.3}}
\newlabel{sect:bitDecomp}{{4.3}{21}{Bit decomposition\relax }{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Definition}{21}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Evaluation on Tdf and Tdf21}{22}{subsection.4.3.2}}
\@writefile{tdo}{\contentsline {todo}{{Should be possible to give some more formal results here.}}{22}{section*.33}}
\pgfsyspdfmark {pgfid52}{26461371}{29029304}
\pgfsyspdfmark {pgfid53}{5539101}{30245945}
\pgfsyspdfmark {pgfid54}{9159964}{28817729}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Sample distributions for an unpartitioned and a 3 bit decomposition prior, over 10,000 samples on the Tdf continuous model.\relax }}{22}{figure.caption.34}}
\newlabel{fig:tdf21PSampDist}{{4.10}{22}{Sample distributions for an unpartitioned and a 3 bit decomposition prior, over 10,000 samples on the Tdf continuous model.\relax \relax }{figure.caption.34}{}}
\@writefile{tdo}{\contentsline {todo}{{talk about how binomials of different depth perform here}}{22}{section*.36}}
\pgfsyspdfmark {pgfid57}{11813820}{11075927}
\pgfsyspdfmark {pgfid58}{5539101}{12349898}
\pgfsyspdfmark {pgfid59}{9159964}{10864352}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Sample distributions for an unpartitioned and a 3 bit decomposition prios, over 10,000 samples on the Tdf21 model.\relax }}{23}{figure.caption.35}}
\newlabel{fig:tdf21PSampDist}{{4.11}{23}{Sample distributions for an unpartitioned and a 3 bit decomposition prios, over 10,000 samples on the Tdf21 model.\relax \relax }{figure.caption.35}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Expected number of steps to neighbourhoods of the mode on the Tdf and Tdf21 continuous models for an unpartitioned prior, the (1,2,95) sum decomposition and 2 bit decompositions.\relax }}{23}{table.caption.37}}
\newlabel{tab:bestParts}{{4.3}{23}{Expected number of steps to neighbourhoods of the mode on the Tdf and Tdf21 continuous models for an unpartitioned prior, the (1,2,95) sum decomposition and 2 bit decompositions.\relax \relax }{table.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Getting stuck on a bad sample}{23}{subsection.4.3.3}}
\newlabel{sect:stuckSamples}{{4.3.3}{23}{Getting stuck on a bad sample\relax }{subsection.4.3.3}{}}
\@writefile{tdo}{\contentsline {todo}{{is a more thorough analysis feasible here?}}{24}{section*.38}}
\pgfsyspdfmark {pgfid62}{15763512}{19835906}
\pgfsyspdfmark {pgfid63}{5539101}{20618357}
\pgfsyspdfmark {pgfid64}{9159964}{19624331}
\@writefile{tdo}{\contentsline {todo}{{add more analysis on this}}{24}{section*.39}}
\pgfsyspdfmark {pgfid67}{31781332}{8126807}
\pgfsyspdfmark {pgfid68}{5539101}{8851928}
\pgfsyspdfmark {pgfid69}{9159964}{7915232}
\@writefile{tdo}{\contentsline {todo}{{explain why this is wrong}}{25}{section*.40}}
\pgfsyspdfmark {pgfid72}{12741094}{34389610}
\pgfsyspdfmark {pgfid75}{33522973}{35172061}
\pgfsyspdfmark {pgfid76}{37143836}{34178035}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Mixtures of shifted bit decompositions}{25}{subsection.4.3.4}}
\newlabel{sect:shifts}{{4.3.4}{25}{Mixtures of shifted bit decompositions\relax }{subsection.4.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Avoiding getting stuck}{25}{section*.41}}
\newlabel{sect:stuckMath}{{4.3.4}{25}{Avoiding getting stuck\relax }{section*.41}{}}
\@writefile{tdo}{\contentsline {todo}{{fix the math formatting in this section}}{25}{section*.42}}
\pgfsyspdfmark {pgfid77}{6571294}{21350942}
\pgfsyspdfmark {pgfid80}{33522973}{22076063}
\pgfsyspdfmark {pgfid81}{37143836}{21139367}
\@writefile{toc}{\contentsline {subsubsection}{Empirical performance}{27}{section*.43}}
\newlabel{fig:allMaxShifts}{{4.12a}{27}{Maximum sized shifts.\relax \relax }{figure.caption.44}{}}
\newlabel{sub@fig:allMaxShifts}{{a}{27}{Maximum sized shifts.\relax \relax }{figure.caption.44}{}}
\newlabel{fig:allMinShifts}{{4.12b}{27}{Minimum sized shifts.\relax \relax }{figure.caption.44}{}}
\newlabel{sub@fig:allMinShifts}{{b}{27}{Minimum sized shifts.\relax \relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Time to 0.001 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax }}{27}{figure.caption.44}}
\newlabel{fig:allShifts}{{4.12}{27}{Time to 0.001 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax \relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax }}{28}{figure.caption.45}}
\newlabel{fig:AllShiftsMax001}{{4.13}{28}{Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depths using a shift for every bit.\relax \relax }{figure.caption.45}{}}
\@writefile{tdo}{\contentsline {todo}{{talk about distributions over shifts, and more about benefits/drawback of shifts and/or changing depths}}{28}{section*.46}}
\pgfsyspdfmark {pgfid82}{9913630}{20513210}
\pgfsyspdfmark {pgfid83}{5539101}{22770221}
\pgfsyspdfmark {pgfid84}{9159964}{20301635}
\@writefile{toc}{\contentsline {subsubsection}{Determining optimal shifts and shift transitions}{28}{section*.48}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depth using a small number of shifts.\relax }}{29}{figure.caption.47}}
\newlabel{fig:fewShifts}{{4.14}{29}{Time to 0.01 neighbourhood of mode, averaged over all mode placements, for bit decompositions of different depth using a small number of shifts.\relax \relax }{figure.caption.47}{}}
\@writefile{tdo}{\contentsline {todo}{{There seem to be heuristic ways to address this}}{29}{section*.49}}
\pgfsyspdfmark {pgfid87}{8209696}{15150053}
\pgfsyspdfmark {pgfid90}{33522973}{15932504}
\pgfsyspdfmark {pgfid91}{37143836}{14938478}
\@writefile{tdo}{\contentsline {todo}{{try to get some results using markov chain implementation. Otherwise there's not much point in describing it ...}}{29}{section*.50}}
\pgfsyspdfmark {pgfid92}{6571294}{9448421}
\pgfsyspdfmark {pgfid95}{33522973}{11705432}
\pgfsyspdfmark {pgfid96}{37143836}{9236846}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Novel PPL inference techniques}{31}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:infEngines}{{5}{31}{Novel PPL inference techniques\relax }{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Preliminaries}{31}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Slice sampling}{31}{subsection.5.1.1}}
\newlabel{sect:sliceBack}{{5.1.1}{31}{Slice sampling\relax }{subsection.5.1.1}{}}
\@writefile{tdo}{\contentsline {todo}{{add basic description of slice sampling}}{31}{section*.51}}
\pgfsyspdfmark {pgfid97}{6571294}{12910183}
\pgfsyspdfmark {pgfid100}{33522973}{13692634}
\pgfsyspdfmark {pgfid101}{37143836}{12698608}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Basic PPL Construction}{31}{subsection.5.1.2}}
\@writefile{tdo}{\contentsline {todo}{{add basic description of lightweight style PPL construction}}{31}{section*.52}}
\pgfsyspdfmark {pgfid102}{6571294}{8126807}
\pgfsyspdfmark {pgfid105}{33522973}{9343448}
\pgfsyspdfmark {pgfid106}{37143836}{7915232}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Stochastic Python}{32}{section.5.2}}
\newlabel{sect:StocPy}{{5.2}{32}{Stochastic Python\relax }{section.5.2}{}}
\@writefile{tdo}{\contentsline {todo}{{add description of implementation, space permitting}}{32}{section*.53}}
\pgfsyspdfmark {pgfid107}{9913630}{44636889}
\pgfsyspdfmark {pgfid108}{5539101}{45620214}
\pgfsyspdfmark {pgfid109}{9159964}{44134668}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Slice sampling inference engine}{32}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Custom Slice Sampling and Metropolis on Tdf models}{32}{subsection.5.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Burn-in time for local metropolis-hastings and slice sampling, on the two continuous Tdf models, as the target neighbourhood varies.\relax }}{32}{figure.caption.54}}
\newlabel{fig:SliceMetCustPerf}{{5.1}{32}{Burn-in time for local metropolis-hastings and slice sampling, on the two continuous Tdf models, as the target neighbourhood varies.\relax \relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Average burn-in time for slice sampling guided by a Gaussian likelihood of varying mean and standard deviation\relax }}{33}{figure.caption.55}}
\newlabel{fig:sliceGaussLik}{{5.2}{33}{Average burn-in time for slice sampling guided by a Gaussian likelihood of varying mean and standard deviation\relax \relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces The smallest and largest Gaussian standard deviation considered in Figure \ref  {fig:sliceGaussLik}\relax }}{33}{figure.caption.56}}
\newlabel{fig:gaussStdDev}{{5.3}{33}{The smallest and largest Gaussian standard deviation considered in Figure \ref {fig:sliceGaussLik}\relax \relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Sample evolution of local metropolis and slice sampling on the Tdf continuous model\relax }}{34}{figure.caption.57}}
\newlabel{fig:custSampEvol}{{5.4}{34}{Sample evolution of local metropolis and slice sampling on the Tdf continuous model\relax \relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Sample autocorrelation of local metropolis and slice sampling on the Tdf continuous model\relax }}{34}{figure.caption.58}}
\newlabel{fig:custAutoCorr}{{5.5}{34}{Sample autocorrelation of local metropolis and slice sampling on the Tdf continuous model\relax \relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Empirical sample distribution of local metropolis and slice sampling on the Tdf continuous model\relax }}{34}{figure.caption.59}}
\newlabel{fig:custSampDist}{{5.6}{34}{Empirical sample distribution of local metropolis and slice sampling on the Tdf continuous model\relax \relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Generic, lightweight, slice sampling inference engine}{35}{subsection.5.3.2}}
\@writefile{tdo}{\contentsline {todo}{{change this after bibliography exists}}{35}{section*.60}}
\pgfsyspdfmark {pgfid112}{28003614}{40886488}
\pgfsyspdfmark {pgfid115}{33522973}{41668939}
\pgfsyspdfmark {pgfid116}{37143836}{40674913}
\@writefile{toc}{\contentsline {subsubsection}{Slice sampling on the Tdf model}{35}{section*.61}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Sample distribution from running Venture and stochastic python versions of metropolis and slice sampling for 10 minutes on the Tdf continuous model.\relax }}{36}{figure.caption.62}}
\newlabel{fig:tdfSampDists}{{5.7}{36}{Sample distribution from running Venture and stochastic python versions of metropolis and slice sampling for 10 minutes on the Tdf continuous model.\relax \relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Comparison of Kolmogorov-Smirnov differences between true and inferred posteriors.\relax }}{36}{figure.caption.63}}
\newlabel{fig:TdfSliceLIComp}{{5.8}{36}{Comparison of Kolmogorov-Smirnov differences between true and inferred posteriors.\relax \relax }{figure.caption.63}{}}
\@writefile{toc}{\contentsline {subsubsection}{Slice sampling on gaussian mean inference models}{36}{section*.64}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Analytically derived posteriors of the NormalMean1, NormalMean2 and NormalMean3 models.\relax }}{37}{figure.caption.65}}
\newlabel{fig:tdfSampDists}{{5.9}{37}{Analytically derived posteriors of the NormalMean1, NormalMean2 and NormalMean3 models.\relax \relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 1 dimensional NormalMean1 model.\relax }}{38}{figure.caption.66}}
\newlabel{fig:normal1Perf}{{5.10}{38}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 1 dimensional NormalMean1 model.\relax \relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 2 dimensional NormalMean2 model.\relax }}{38}{figure.caption.67}}
\newlabel{fig:normal2Perf}{{5.11}{38}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the 2 dimensional NormalMean2 model.\relax \relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the trans-dimensional NormalMean3 model.\relax }}{39}{figure.caption.68}}
\newlabel{fig:normal4Perf}{{5.12}{39}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the trans-dimensional NormalMean3 model.\relax \relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {subsubsection}{Branching Model}{39}{section*.69}}
\newlabel{sect:branching}{{5.3.2}{39}{Branching Model\relax }{section*.69}{}}
\@writefile{tdo}{\contentsline {todo}{{change this once bibliography exists}}{39}{section*.70}}
\pgfsyspdfmark {pgfid117}{10726354}{25519896}
\pgfsyspdfmark {pgfid120}{33522973}{26302347}
\pgfsyspdfmark {pgfid121}{37143836}{25308321}
\@writefile{tdo}{\contentsline {todo}{{mention the discrepancy with the paper?}}{39}{section*.71}}
\pgfsyspdfmark {pgfid122}{17139390}{10560322}
\pgfsyspdfmark {pgfid125}{33522973}{11342773}
\pgfsyspdfmark {pgfid126}{37143836}{10348747}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces True posterior for the Branching Model\relax }}{40}{figure.caption.72}}
\newlabel{fig:BranchPost}{{5.13}{40}{True posterior for the Branching Model\relax \relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax }}{40}{figure.caption.73}}
\newlabel{fig:branchPerf}{{5.14}{40}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.73}{}}
\@writefile{tdo}{\contentsline {todo}{{talk about the continuous vs. discrete aspect and the domain in which we expect slice to be good}}{41}{section*.74}}
\pgfsyspdfmark {pgfid127}{25768654}{32072932}
\pgfsyspdfmark {pgfid130}{33522973}{34329943}
\pgfsyspdfmark {pgfid131}{37143836}{31861357}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax }}{41}{figure.caption.75}}
\newlabel{fig:branchPerfSamps}{{5.15}{41}{Runs and quartiles generated by slice, metropolis and mixtures of metropolis and slice on the Branching model.\relax \relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {subsubsection}{Trans-dimensional slice sampling}{42}{section*.76}}
\newlabel{sect:tdSlice}{{5.3.2}{42}{Trans-dimensional slice sampling\relax }{section*.76}{}}
\newlabel{fig:branchTraceLik}{{5.16a}{42}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.77}{}}
\newlabel{sub@fig:branchTraceLik}{{a}{42}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.77}{}}
\newlabel{fig:branchPost}{{5.16b}{42}{True posterior of Branching model.\relax \relax }{figure.caption.77}{}}
\newlabel{sub@fig:branchPost}{{b}{42}{True posterior of Branching model.\relax \relax }{figure.caption.77}{}}
\@writefile{tdo}{\contentsline {todo}{{mention buggy metropolis version that also samples from this}}{43}{section*.78}}
\pgfsyspdfmark {pgfid132}{8338514}{45678935}
\pgfsyspdfmark {pgfid135}{33522973}{45620214}
\pgfsyspdfmark {pgfid136}{37143836}{44134668}
\newlabel{fig:branchWrongTraceLik}{{5.16c}{43}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.79}{}}
\newlabel{sub@fig:branchWrongTraceLik}{{c}{43}{Space of trace likelihoods if both variables are always sampled.\relax \relax }{figure.caption.79}{}}
\newlabel{fig:branchWrongPost}{{5.16d}{43}{Space of trace likelihoods implied by naive slice sampling.\relax \relax }{figure.caption.79}{}}
\newlabel{sub@fig:branchWrongPost}{{d}{43}{Space of trace likelihoods implied by naive slice sampling.\relax \relax }{figure.caption.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the modified and the naive slice algorithms on the NormalMean3 model.\relax }}{44}{figure.caption.80}}
\newlabel{fig:normal4TD}{{5.16}{44}{Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the modified and the naive slice algorithms on the NormalMean3 model.\relax \relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the corrected slice and the naive slice algorithms on the Branching model.\relax }}{44}{figure.caption.81}}
\newlabel{fig:branchTD}{{5.17}{44}{Runs and quartiles generated by metropolis, a mixture of metropolis and slice, and both the corrected slice and the naive slice algorithms on the Branching model.\relax \relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Quasi-Monte Carlo}{44}{section.5.4}}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Summary and Conclusions}{47}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
