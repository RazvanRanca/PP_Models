\chapter{Summary and Conclusions}
\label{chap:conc}

\section{Overview}
We've performed an empirical evaluation of OpenBUGS and Venture on a few simple models and shown that OpenBUGS significantly outperforms Venture. This discrepancy in performance is partly atributable to the fact that OpenBUGS sacrifices some expresivity in exchange for efficiency. However there is no good reason to believe that Venture's flexibility has to come at such a high computational cost. In particular, OpenBUGS employs a large array of inference methods and employs an expert system to decide which method to apply to which model. It seems that high-level probabilistic programming languages such as Venture could employ similar systems as to be able to apply less general but more efficient inference algorithms on certain classes of models.

We've explored a pre-processing technique that aims to compile probabilistic programs into equivalent but more efficient versions of themselves. We show, that on some models, large performance gains can be made by this technique, but that the general case is more difficult to solve. We also present some negative results, detailing why some a-priori plausible solutions either do not leave our programs invariant or do not have good empirical performance.

Towards improving inference performance in Turing Complete PPLs, we implemented such a language in python and made it available online. We then implemented a slice sampling inference engine in our PPL, thus exploring an inference technique which hadn't previously been used in the context of probabilistic programs. We show that slice sampling can lead to large speed-ups on certain models and discuss the problem of making slice sampling work correctly on trans-dimensional probabilistic spaces. We also provide a negative result here, showing that one reasonable solution to the trans-dimensional slicing fails on some models (though it suceeds on others).

\section{Future Directions}
Both OpenBUGS and Venture are used on a large variety of models with varying qualities of model specification and varying user expectations. As such it would be interesting to conduct a more comprehensive comparison of the two languages, which would cover a much wider variety of models and inference requirements than we have done. Additionally, Venture offers us the tools to tweak its inference engine or even provide an external, bespoke, inference technique for parts of a model. As such it would be interesting to see what level of customization would need to be done to Venture's inference engine before the performance it obtained on certain models was on par with OpenBUGS.

Our analysis of partitioned priors has clearly shown that this technique can significantly speed up inference on some models, but that it can also hinder performance on others. It would be useful to perform a thorough, theoretical or empirical, analysis trying to define the class of models in which partitioned priors would help. It would also be interesting to test the effect of the sum partition method on infinitely divisible prior distributions. Additional techniques for preventing stuck bits should also be investigated, such as the mixture over bit decompositions of different depths. 

For slice sampling, the main problem is devising a trans-dimensional approach which is usable on arbitrary probabilistic programs, or proving that this is impossible. Assuming a trans-dimensional slicer exists, then it would be very interesting to determine the class of models on which slice sampling outperform metropolis-hastings. Our preliminary results (as well as previous slice sampling literature \cite{}) seem to indicate that slice sampling is well suited for continuous, low-dimensional model. Versions of slice sampling which are designed to handle high-dimensional cases better should also be investigated. Finally, in order for stochastic python to be generally usable as a PPL, the interface should be made more user-friendly by automatically inferring the name that should be given to random variables, rather than having the user provide them.


